{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":19991,"databundleVersionId":1117522,"sourceType":"competition"},{"sourceId":7115099,"sourceType":"datasetVersion","datasetId":4103208}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:01.466305Z","iopub.execute_input":"2023-12-03T20:08:01.466961Z","iopub.status.idle":"2023-12-03T20:08:01.474291Z","shell.execute_reply.started":"2023-12-03T20:08:01.466906Z","shell.execute_reply":"2023-12-03T20:08:01.472889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n# from tensorflow.keras.applications.efficientnet import EfficientNetB3\nfrom tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0, EfficientNetV2B3, EfficientNetV2S\n# from tf.keras.applications.efficientnet import EfficientNetB3\nfrom sklearn import metrics\nprint(\"hi\")\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-03T20:08:01.476729Z","iopub.execute_input":"2023-12-03T20:08:01.478040Z","iopub.status.idle":"2023-12-03T20:08:01.487038Z","shell.execute_reply.started":"2023-12-03T20:08:01.477978Z","shell.execute_reply":"2023-12-03T20:08:01.485616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"hi\")\n\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:01.489105Z","iopub.execute_input":"2023-12-03T20:08:01.489652Z","iopub.status.idle":"2023-12-03T20:08:01.535585Z","shell.execute_reply.started":"2023-12-03T20:08:01.489613Z","shell.execute_reply":"2023-12-03T20:08:01.534700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/hi.txt', 'w') as file:\n    file.write(\"hi\")\n    file.close()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:01.541810Z","iopub.execute_input":"2023-12-03T20:08:01.542287Z","iopub.status.idle":"2023-12-03T20:08:01.548315Z","shell.execute_reply.started":"2023-12-03T20:08:01.542244Z","shell.execute_reply":"2023-12-03T20:08:01.547071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l /kaggle/working/efficientnetv2_s.train-n-240000.weights.01-0.7304.h5","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:01.550003Z","iopub.execute_input":"2023-12-03T20:08:01.550868Z","iopub.status.idle":"2023-12-03T20:08:02.628259Z","shell.execute_reply.started":"2023-12-03T20:08:01.550817Z","shell.execute_reply":"2023-12-03T20:08:02.626494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU Strategy and other configs ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint('hi')\n\n# Detect and initialize TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()  # Default strategy for CPU and single GPU\n\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:02.630562Z","iopub.execute_input":"2023-12-03T20:08:02.631105Z","iopub.status.idle":"2023-12-03T20:08:02.641299Z","shell.execute_reply.started":"2023-12-03T20:08:02.631043Z","shell.execute_reply":"2023-12-03T20:08:02.639797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -r /kaggle/input/alaska2-image-steganalysis/Test\n# !rm /kaggle/input/alaska2-image-steganalysis/sample_submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:02.643255Z","iopub.execute_input":"2023-12-03T20:08:02.643791Z","iopub.status.idle":"2023-12-03T20:08:02.652145Z","shell.execute_reply.started":"2023-12-03T20:08:02.643744Z","shell.execute_reply":"2023-12-03T20:08:02.651205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup the Tensorflow datasets (train and val), data augmentations, and oversampling if necessary","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\n# Constants\nbase_dir = '/kaggle/input/alaska2-image-steganalysis/'\nclass_names = ['Cover', 'JMiPOD', 'UERD', 'JUNIWARD']\n# class_names = ['Cover', 'JMiPOD']\n\nimage_size = (512, 512)\n# 20 for effnet-M, 32 for effnet-S\nbatch_size = 32 * strategy.num_replicas_in_sync\naugmented_batch_size = 4\n        \ndef get_paths(split_at, end_at, oversample=True,multiclass=False):\n    \n    train_class_paths_array = []\n    val_class_paths_array = []\n    \n    for class_name in class_names:\n        class_dir = os.path.join(base_dir, class_name)\n        all_images = os.listdir(class_dir) \n\n        selected_images = all_images[:end_at]  \n        \n        train_class_paths = []\n        val_class_paths = []\n            \n        for img in selected_images[:split_at]:\n            train_class_paths.append(os.path.join(class_dir, img))           \n                \n        for img in selected_images[split_at:]:\n            val_class_paths.append(os.path.join(class_dir, img))            \n        \n        train_class_paths_array.append(train_class_paths)\n        val_class_paths_array.append(val_class_paths)\n#     if multiclass:\n#             val_labels.append(tf.one_hot(class_names.index(class_name), len(class_names)))\n    \n    train_data_paths = []\n    val_data_paths = []\n    \n    # 'Cover' paths must be first in array\n    for i, cover_path in enumerate(train_class_paths_array[0]):\n        if not oversample:\n            train_data_paths.append(cover_path)\n        for j in range(1, 4): # 1, 2 ,3\n            if oversample:\n                train_data_paths.append(cover_path)\n            train_data_paths.append(train_class_paths_array[j][i])\n        \n    for i, cover_path in enumerate(val_class_paths_array[0]):\n        if not oversample:\n            val_data_paths.append(cover_path)\n        for j in range(1, 4): # 1, 2 ,3\n            if oversample:\n                val_data_paths.append(cover_path)\n            val_data_paths.append(val_class_paths_array[j][i])\n    \n    train_labels = [0 if 'Cover' in path else 1 for path in train_data_paths]\n    val_labels = [0 if 'Cover' in path else 1 for path in val_data_paths]\n    \n    return train_data_paths, val_data_paths, train_labels, val_labels\n\n# 80/20 split\n# split_at = 25600\n# end_at = 32000\nsplit_at = 60000\nend_at = 75000\n\ntrain_data_paths, val_data_paths, train_labels, val_labels = get_paths(split_at, end_at, oversample=True)\n\nprint(train_data_paths[:10])\nprint(val_data_paths[:10])\n\ntrain_labels = tf.cast(train_labels, tf.float32)\nval_labels = tf.cast(val_labels, tf.float32)\n\ntrain_len = len(train_data_paths)\nval_len = len(val_data_paths)\n\npreprocessor = tf.keras.applications.resnet50.preprocess_input\npreprocess = False # If preprocessing is needed, EfficientNetV2 has a preprocessing layer doesn't need it\naugment = True    \n\n# Function to load and preprocess an image\ndef load_and_preprocess_image(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.cast(img, tf.float32)\n    if preprocess:\n        img = preprocessor(img)  # Resnet preprocessing\n        img = img / 255.0\n    if augment:\n        img = augment_image(img)\n    return img\n\n# Function to apply data augmentation to an image\ndef augment_image(img):\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_flip_up_down(img)\n    # Add more augmentation techniques as needed\n    return img\n\n# # Function to create a batch of augmented images\n# def create_augmented_batch(img):\n#     augmented_images = [augment_image(img) for _ in range(augmented_batch_size)]  # Create 4 augmented images\n#     return tf.stack(augmented_images)\n\n# for x, y in train_data_paths:\n#     print(x, y)\n#     load_and_preprocess_image(x, y)\n\n# Create datasets inside strategy.scope()\nwith strategy.scope():\n    train_dataset = (\n        tf.data.Dataset\n        .from_tensor_slices((train_data_paths, train_labels))\n#         .shuffle(buffer_size=len(train_labels), seed=42)\n        .map(lambda img_path, label: (load_and_preprocess_image(img_path), label))\n        .batch(batch_size)\n        .repeat()\n        .prefetch(buffer_size=tf.data.AUTOTUNE)\n    )\n    print('train dataset')\n    \n    val_dataset = (\n        tf.data.Dataset\n        .from_tensor_slices((val_data_paths, val_labels))\n#         .shuffle(buffer_size=len(val_labels), seed=42)\n        .map(lambda img_path, label: (load_and_preprocess_image(img_path), label))\n        .batch(batch_size)\n        .repeat()\n        .prefetch(buffer_size=tf.data.AUTOTUNE)\n    )\n#     val_dataset = tf.data.Dataset.from_tensor_slices((val_data_paths, val_labels))\n#     val_dataset = val_dataset.map(lambda img_path, label: (load_and_preprocess_image(img_path), label))\n#     val_dataset = val_dataset.shuffle((end_at - split_at)).repeat().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n    print('val datasset')\n    \n    # Check the dataset shapes\n    for image, label in train_dataset.take(1):\n        print(\"Training Batch - Image Shape:\", image.shape, \"Label:\", label)\n        print(tf.math.reduce_max(image))\n        print(tf.math.reduce_min(image))        \n    for image, label in val_dataset.take(1):\n        print(\"Validation Batch - Image Shape:\", image.shape, \"Label:\", label)\n        print(tf.math.reduce_max(image))\n        print(tf.math.reduce_min(image)) \n    print(\"Train len: \", train_len)\n    print(\"Val len: \", val_len)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:02.653771Z","iopub.execute_input":"2023-12-03T20:08:02.654791Z","iopub.status.idle":"2023-12-03T20:08:06.437891Z","shell.execute_reply.started":"2023-12-03T20:08:02.654751Z","shell.execute_reply":"2023-12-03T20:08:06.436562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# import tensorflow as tf\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # Define the base directory containing the 'Cover', 'JMiPOD', 'UERD', and 'JUNIWARD' folders\n# base_dir = '/kaggle/input/alaska2-image-steganalysis'\n\n# # Specify image size and batch size\n# img_size = (512, 512)\n# batch_size = 32 * strategy.num_replicas_in_sync\n\n# # Configuration\n# # epochs = 20\n\n# # Define data augmentation parameters\n# datagen = ImageDataGenerator(\n# #     rescale=1./255,\n#     horizontal_flip=True,\n#     vertical_flip=True,\n#     validation_split=0.2  # 20% of the data will be used for validation\n# )\n\n# with strategy.scope():\n\n#     print(\"starting train gen\")\n#     # Create a generator for training data\n#     train_generator = datagen.flow_from_directory(\n#         base_dir,\n#         target_size=img_size,\n#         batch_size=batch_size,\n#         classes=['Cover', 'JMiPOD', 'JUNIWARD', 'UERD'],\n#         class_mode='categorical',\n#         subset='training',  # Specify that this is the training subset\n#     )\n    \n#     # Create a generator for validation data\n#     validation_generator = datagen.flow_from_directory(\n#         base_dir,\n#         target_size=img_size,\n#         batch_size=batch_size,\n#         classes=['Cover', 'JMiPOD', 'JUNIWARD', 'UERD'],\n#         class_mode='categorical',\n#         subset='validation',  # Specify that this is the validation subset\n#     )\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:06.439850Z","iopub.execute_input":"2023-12-03T20:08:06.440278Z","iopub.status.idle":"2023-12-03T20:08:06.446846Z","shell.execute_reply.started":"2023-12-03T20:08:06.440242Z","shell.execute_reply":"2023-12-03T20:08:06.445226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_dummy_image(shape=(512, 512, 3)):\n#     return np.random.rand(*shape).astype('float32') / 255.0\n\n# def generate_dummy_label(num_classes=10):\n#     return np.random.randint(num_classes, size=1)[0]\n\n# def create_dummy_dataset(num_samples, num_classes=10, batch_size=32):\n#     images = [generate_dummy_image() for _ in range(num_samples)]\n#     labels = [generate_dummy_label(num_classes) for _ in range(num_samples)]\n#     labels_one_hot = [tf.one_hot(label, num_classes) for label in labels]\n    \n#     dataset = tf.data.Dataset.from_tensor_slices((images, labels_one_hot))\n#     dataset = dataset.shuffle(buffer_size=num_samples)\n#     dataset = dataset.batch(batch_size)\n    \n#     return dataset\n\n# # Example usage:\n# train_samples = 128\n# validation_samples = 64\n# num_classes = 4\n# batch_size = 32\n\n# with strategy.scope():\n\n#     train_generator = create_dummy_dataset(train_samples, num_classes, batch_size)\n#     validation_generator = create_dummy_dataset(validation_samples, num_classes, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:06.452931Z","iopub.execute_input":"2023-12-03T20:08:06.453519Z","iopub.status.idle":"2023-12-03T20:08:06.463368Z","shell.execute_reply.started":"2023-12-03T20:08:06.453481Z","shell.execute_reply":"2023-12-03T20:08:06.461835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define and Compile Model, Loss function, Optimizer, Metrics","metadata":{}},{"cell_type":"code","source":"# base_model = EfficientNetV2(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\nfrom tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0, EfficientNetV2B3, EfficientNetV2S, EfficientNetV2M, EfficientNetV2L\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nwith strategy.scope():\n\n#     tf.keras.applications.efficientnet_v2.EfficientNetV2B3(\n#         include_top=False,\n#         weights='imagenet',\n#         input_tensor=None,\n#         input_shape=None,\n#         pooling=None,\n#     #     classes=1000,\n#         classifier_activation='softmax',\n# #         include_preprocessing=True # should rescale for us\n#     )\n    \n    # Image preprocessing (normalization) included in implementation\n    # https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/preprocess_input \n    base_model = EfficientNetV2S(\n        include_top=False,\n        weights=None,\n#         input_tensor=None,\n        input_shape=(512,512, 3),\n#         pooling=None,\n#         classes=num_classes,\n#         classifier_activation='softmax',\n        include_preprocessing=True \n    )\n    \n#     base_model = EfficientNetV2M(\n#         include_top=False,\n#         weights=None,\n#         input_shape=(512,512, 3),\n#         include_preprocessing=True \n#     )\n    \n#     base_model = ResNet50(\n#         include_top=False,\n#         weights=None,\n# #         input_tensor=None,\n#         input_shape=(512, 512, 3),\n# #         pooling='avg',\n# #         classes=4,\n#     )\n\n    # If we want to fine-tune\n#     for layer in base_model.layers:\n#         layer.trainable = False   \n#     model_name = 'resnet50'\n    model_name = 'efficientnetv2_s'\n    pretrained = False    \n    num_classes = 4\n    \n    model = tf.keras.Sequential([\n        base_model,\n        L.GlobalAveragePooling2D(),\n        L.Dropout(0.2),\n        L.Dense(1, activation='sigmoid') # One output for binary classification\n#         tf.keras.layers.Dense(num_classes, activation='softmax')\n#         SimpleAttention(),\n#         L.Flatten(),\n#         L.Dense(units=256), # one for each pixel (16 x 16)\n#         L.Dropout(0.5),\n#         L.Dense(num_classes, activation='softmax') \n    ])\n\n\n    print(model.summary())\n\n    model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-5),\n                  loss=tf.keras.losses.BinaryCrossentropy(),\n                  metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.F1Score()]) # try f1-score\n#     model.compile(optimizer='adam',\n#                   loss='categorical_crossentropy',\n#                   metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:06.490820Z","iopub.execute_input":"2023-12-03T20:08:06.491912Z","iopub.status.idle":"2023-12-03T20:08:14.354913Z","shell.execute_reply.started":"2023-12-03T20:08:06.491863Z","shell.execute_reply":"2023-12-03T20:08:14.353974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Callback to save a running history of important metrics each epoch","metadata":{}},{"cell_type":"code","source":"import pickle\nfrom tensorflow.keras.callbacks import Callback\n\nclass SaveHistoryCallback(Callback):\n    def __init__(self, filename=f'/kaggle/working/no_shuffle_{model_name}' + ('.pretrained' if pretrained else '') + f'.train-n-{train_len}.running_history.pkl'):\n        super(SaveHistoryCallback, self).__init__()\n        self.filename = filename\n        self.history = {\n            \"loss\": [],\n            \"accuracy\": [],\n            \"val_loss\": [],\n            \"val_accuracy\": [],\n            \"precision\": [],\n            \"recall\": [],\n            \"f1_score\": []\n        }\n    \n    def on_epoch_end(self, epoch, logs=None):\n#         current_epoch_data = {\n#             'epoch': epoch,\n#             'logs': logs.copy() if logs else None\n#         }        \n        if logs is not None:\n            # Access training metrics for the current epoch\n            loss = logs.get('loss')\n            accuracy = logs.get('accuracy')\n            \n            # Access validation metrics if available\n            val_loss = logs.get('val_loss')\n            val_accuracy = logs.get('val_accuracy')\n\n            self.history[\"loss\"].append(loss)\n            self.history[\"accuracy\"].append(accuracy)\n            self.history[\"val_loss\"].append(val_loss)\n            self.history[\"val_accuracy\"].append(val_accuracy)\n            \n            precision = logs.get('precision')\n            recall = logs.get('recall')\n            f1_score = logs.get('f1_score')\n            \n            self.history[\"precision\"].append(precision)\n            self.history[\"recall\"].append(recall)\n            self.history[\"f1_score\"].append(f1_score)\n\n#             with open(self.filename, 'w') as file:\n#                 json.dump(self.history, file)\n#                 print(f'saved to {self.filename}')\n            with open(self.filename, 'wb') as file:\n                print(f'saved history to {self.filename}')\n                pickle.dump(self.history, file)\n        else:\n            print('logs unexpectedly none in SaveHistoryCallback')\n\n#             # Custom actions based on metrics\n#             print(f' Epoch {epoch + 1}: Val Loss={val_loss:.4f}, Val Accuracy={val_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:14.356500Z","iopub.execute_input":"2023-12-03T20:08:14.356835Z","iopub.status.idle":"2023-12-03T20:08:14.369599Z","shell.execute_reply.started":"2023-12-03T20:08:14.356804Z","shell.execute_reply":"2023-12-03T20:08:14.368312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load a checkpoint if necessary","metadata":{}},{"cell_type":"code","source":"load_checkpoint = True\n# load_path = '/kaggle/working/efficientnetv2_s.train-n-240000.weights.01-0.7304.h5'\nload_path = '/kaggle/input/binary-effnetv2/binary_no_shuffle_efficientnetv2_s.train-n-360000.weights.06-0.5020.h5'\n\nif load_checkpoint:\n    model.load_weights(load_path)\n    print(f'loaded from {load_path}')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:14.370967Z","iopub.execute_input":"2023-12-03T20:08:14.371367Z","iopub.status.idle":"2023-12-03T20:08:15.942219Z","shell.execute_reply.started":"2023-12-03T20:08:14.371333Z","shell.execute_reply":"2023-12-03T20:08:15.941033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model (with checkpoints and scheduler)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nnum_epochs = 7\n\nwith strategy.scope():\n#     checkpoint = ModelCheckpoint('/kaggle/input/weights.{epoch:02d}-{val_loss:.2f}.h5', save_freq=1, monitor='val_loss', save_best_only=True)\n    \n    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath='/kaggle/working/binary_no_shuffle_' + model_name + ('.pretrained' if pretrained else '') + '.train-n-' + str(train_len) + '.weights.{epoch:02d}-{val_accuracy:.4f}.h5',\n        save_weights_only=True,\n        verbose=1,\n        monitor='val_accuracy',\n#         mode='max',\n#         save_best_only=True\n    )\n    \n    lr_scheduler = ReduceLROnPlateau(\n        monitor='val_f1_score',  \n        factor=0.1,           # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n        patience=2,           # Number of epochs with no improvement after which learning rate will be reduced\n        min_lr=1e-8,          # Minimum learning rate\n        verbose=2             # 1 for progress bar, 2 for logs (when running in background)\n    )\n    \n    multiclass = False\n    \n    # Calculate class weights based on the distribution of classes\n#     class_weights = {\n#         0: 1.0,  # weight for class 0 (e.g., cover images)\n#         1: train_len / (3 * train_len),  # weight for class 1 (e.g., stego images)\n#     } if multiclass is False else None\n    \n#     print(f'class_weights: {class_weights}')\n    \n    history = model.fit(\n        train_dataset,\n        steps_per_epoch=train_len // batch_size,\n        epochs=num_epochs,        \n        validation_data=val_dataset,\n        validation_steps=val_len // batch_size, \n        callbacks=[checkpoint_callback, SaveHistoryCallback(), lr_scheduler],\n#         verbose=2\n#         class_weight=class_weights\n    )\n    \n    # Save the training history to a file\n#     import pickle\n\n    with open(f'/kaggle/working/no_shuffle_{model_name}' + ('.pretrained' if pretrained else '') + f'.train-n-{train_len}.final_history.pkl', 'wb') as file:\n        pickle.dump(history.history, file)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:08:15.944155Z","iopub.execute_input":"2023-12-03T20:08:15.944652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for images, labels in train_dataset.take(1):\n#     print(model.predict(images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(f'/kaggle/working/binary_no_shuffle_{model_name}.{'pretrained' if pretrained else ''}_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n\n- Confusion Matrix + AUC Curve\n- Accuracy + Loss Graphs","metadata":{}},{"cell_type":"code","source":"# Loads the weights\nload_weights = False\n# load_path = '/kaggle/working/efficientnetv2_s.pretrained.train-n-32000.weights.04-0.7500.h5'\nload_path = '/kaggle/input/binary-effnetv2/binary_no_shuffle_efficientnetv2_s.train-n-360000.weights.06-0.5020.h5'\n# load_path = '/kaggle/working/efficientnetv2_s.train-n-32000.weights.01-0.7489.h5'\n\nif load_weights:\n    model.load_weights(load_path)\n    print(f'loaded weights from {load_path}')\n\n# y_true = np.empty()\n# y_preds = np.empty()\n\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\nimport matplotlib.pyplot as plt\n\n# Initialize empty lists for true labels and predicted probabilities\ny_true = []\ny_pred_prob = []\n\n# Iterate over the validation dataset to get true labels and predicted probabilities\ni = 0\nprint('evaluating to generate plots')\nfor images, labels in val_dataset:    \n    y_true.append(labels.numpy()) \n    y_pred_prob.append(model.predict(images))\n    \n#     if i > 5:\n#         break;\n    \n#     i += 1\n\n# Concatenate the lists to obtain numpy arrays\ny_true = np.concatenate(y_true, axis=0)\ny_pred_prob = np.concatenate(y_pred_prob, axis=0)\nprint(y_pred_prob[:10])\n# print(y_true)\n# print(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert predicted probabilities to binary predictions (0 or 1)\nthreshold = 0.50\ny_pred = tf.cast(tf.math.greater_equal(y_pred_prob, threshold), dtype=tf.int32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unique, idx, counts = tf.unique_with_counts(y_pred_prob.flatten())\n# print(unique, counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true, y_pred))\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(y_true, y_pred)\n\n# Plot Confusion Matrix\nplt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\nclasses = ['Cover', 'Stego']  \ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes)\nplt.yticks(tick_marks, classes)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\n\n# Annotate each cell with its value\nfor i in range(len(classes)):\n    for j in range(len(classes)):\n        plt.text(j, i, str(conf_matrix[i, j]), ha='center', va='center', color='red')\n\nplt.show()\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC Curve\nplt.figure()\nplt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_name = 'resnet50'\n# train_len = 100\n# pretrained = True\n# print('/kaggle/working/' + model_name + '.train-n-' + str(train_len) + '.weights.{epoch:02d}-{val_accuracy:.4f}.h5')\n# print('/kaggle/working/' + model_name + ('.pretrained' if pretrained else '') + '.train-n-' + str(train_len) + '.weights.{epoch:02d}-{val_accuracy:.4f}.h5')\n# print(f'/kaggle/working/{model_name}.train-n-{train_len}.final_history.pkl')\n# print(f'/kaggle/working/{model_name}.train-n-{train_len}.running_history.json')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay, confusion_matrix\n\n# Accuracy and Loss Graphs\n# history = model.fit(train_data, epochs=num_epochs, validation_data=validation_data)\nimport pickle\n\n# num_epochs = 7\n\n# running_history = True\n# # running_history_path = f'/kaggle/working/{model_name}' + ('.pretrained' if pretrained else '') + f'.train-n-{train_len}.' + ('running_history.pkl' if running_history else 'final_history.pkl')\n# running_history_path = '/kaggle/working/efficientnetv2_s.train-n-32000.running_history.pkl'\n# # running_history_path = '/kaggle/working/resnet50.pretrained.train-n-32000.running_history.pkl'\n\n# running_history_path = '/kaggle/working/efficientnetv2_s.train-n-240000.running_history.pkl'\n# running_history_path = '/kaggle/input/binary-effnetv2/no_shuffle_efficientnetv2_s.train-n-360000.running_history.pkl'\n\n# with open(running_history_path, 'rb') as file:\n#     history = pickle.load(file)\n# else:\nhistory = history.history\n\nprint(history)\n\n\nplt.figure()\nplt.plot(range(1, num_epochs + 1), history['accuracy'], label='Training Accuracy')\nplt.plot(range(1, num_epochs + 1), history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.plot(range(1, num_epochs + 1), history['loss'], label='Training Loss')\nplt.plot(range(1, num_epochs + 1), history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}